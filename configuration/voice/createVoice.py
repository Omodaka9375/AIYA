# -*- coding: utf-8 -*-
"""TTS_PWGAN_Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1idqisLKE_xxlGiYyMJqQt6AQ3yF3gJgk

ffmpeg -i <input_file> -af "highpass=f=200, lowpass=f=3000" <output_file>


### Download Models
"""



# official model files are on gdrive but I could not find a way to download from gdrive.
# TTS_MODEL_URL = 'https://www.dropbox.com/sh/z62xzmh6qvmn6r0/AAD2e_aoL6nlwj24gLvsUtj6a?dl=0' 
# PWGAN_MODEL_URL = 'https://www.dropbox.com/sh/fz8iixkhv68zsb4/AABlrNomybrGIinOrgLhZeosa?dl=0'

# !wget -O tts_model.zip --no-check-certificate "$TTS_MODEL_URL" 
# !wget -O pwgan_model.zip --no-check-certificate "$PWGAN_MODEL_URL"

# !unzip tts_model.zip -d tts_model/
# !unzip pwgan_model.zip -d pwgan_model/

# """### Setup Libraries"""

# ! sudo apt-get install espeak

# !git clone https://github.com/mozilla/TTS
# !git clone https://github.com/erogol/ParallelWaveGAN

# # Commented out IPython magic to ensure Python compatibility.
# # %cd TTS
# !git checkout 6977899
# !pip install -r requirements.txt
# !python setup.py install

# # Commented out IPython magic to ensure Python compatibility.
# # %cd ../ParallelWaveGAN/
# !git checkout fca88f9  # checkout to the right version for the model
# # !python setup.py install
# ! pip install .
# # %cd ..

"""### Define TTS function"""


"""### Load Models"""
from random import randrange
from pydub import AudioSegment
from pydub.playback import play
import os
import torch
import yaml
import time
import librosa
import librosa.display
from sys import argv
from TTS.utils.generic_utils import load_config, setup_model
from TTS.utils.text.symbols import symbols, phonemes
from TTS.utils.audio import AudioProcessor
from TTS.utils.synthesis import synthesis
from TTS.utils.visual import visualize

from parallel_wavegan.models import ParallelWaveGANGenerator
from parallel_wavegan.utils.audio import AudioProcessor as AudioProcessorVocoder
import glob
import shutil
import sys
import subprocess


def tts(model, text, CONFIG, use_cuda, ap, use_gl,figures=True, counter=0):
    t_1 = time.time()
    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens = synthesis(model, text, CONFIG, use_cuda, ap, speaker_id, style_wav=None,
                                                                            truncated=False, enable_eos_bos_chars=CONFIG.enable_eos_bos_chars)
    if CONFIG.model == "Tacotron" and not use_gl:
        mel_postnet_spec = ap.out_linear_to_mel(mel_postnet_spec.T).T
    mel_postnet_spec = ap._denormalize(mel_postnet_spec)
    print(mel_postnet_spec.shape)
    print("max- ", mel_postnet_spec.max(), " -- min- ", mel_postnet_spec.min())
    if not use_gl:
        waveform = vocoder_model.inference(torch.FloatTensor(ap_vocoder._normalize(mel_postnet_spec).T).unsqueeze(0), hop_size=ap_vocoder.hop_length)
    if use_cuda:
        waveform = waveform.cpu()
    waveform = waveform.numpy()
    print(waveform.shape)
   # print(" >  Run-time: {}".format(time.time() - t_1))
    if figures:  
        visualize(alignment, mel_postnet_spec, stop_tokens, text, ap.hop_length, CONFIG, ap._denormalize(mel_spec))                                                                       
    os.makedirs('configuration/voice/result', exist_ok=True)
    file_name = "part" + str(counter) + ".wav"   
    out_path = os.path.join('configuration/voice/result/', file_name)
    ap.save_wav(waveform, out_path)
    return alignment, mel_postnet_spec, stop_tokens, waveform


# model paths
TTS_MODEL = "configuration/voice/tts_model/checkpoint_670000.pth.tar"
TTS_CONFIG = "configuration/voice/tts_model/config.json"
PWGAN_MODEL = "configuration/voice/pwgan_model/checkpoint-400000steps.pkl"
PWGAN_CONFIG = "configuration/voice/pwgan_model/config.yml"

# load TTS config
TTS_CONFIG = load_config(TTS_CONFIG)

# load PWGAN config
with open(PWGAN_CONFIG) as f:
    PWGAN_CONFIG = yaml.load(f, Loader=yaml.Loader)
    
# Run FLAGs
use_cuda = False
# Set some config fields manually for testing
TTS_CONFIG.windowing = True
TTS_CONFIG.use_forward_attn = True 

# Set the vocoder
use_gl = False # use GL if True
batched_wavernn = True    # use batched wavernn inference if True

# LOAD TTS MODEL
# multi speaker 
speaker_id = None
speakers = []

# load the model
num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)
model = setup_model(num_chars, len(speakers), TTS_CONFIG)

# load the audio processor
ap = AudioProcessor(**TTS_CONFIG.audio)         

# load model state
cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))

# load the model
model.load_state_dict(cp['model'])
if use_cuda:
    model.cuda()
model.eval()
print(cp['step'])
print(cp['r'])

# set model stepsize
if 'r' in cp:
    model.decoder.set_r(cp['r'])

# load PWGAN
if use_gl == False:
    vocoder_model = ParallelWaveGANGenerator(**PWGAN_CONFIG["generator_params"])
    vocoder_model.load_state_dict(torch.load(PWGAN_MODEL, map_location="cpu")["model"]["generator"])
    vocoder_model.remove_weight_norm()
    ap_vocoder = AudioProcessorVocoder(**PWGAN_CONFIG['audio'])    
    if use_cuda:
        vocoder_model.cuda()
    vocoder_model.eval()

data = ''
with open('configuration/text/result/final.txt', 'r') as myfile:
    data=myfile.read()

data = data.replace(';', '')
sentence = data.split('.')

sentencesClean = []
for x in sentence[:-1]:
    if x[0] == ' ':
        sentencesClean.append(x.replace(' ','',1) + '.')
    else: 
        sentencesClean.append(x + '.')


print('createVoice165:\n' + str(sentencesClean))

counter=0
for sent in sentencesClean:
  align, spec, stop_tokens, wav = tts(model, sent, TTS_CONFIG, use_cuda, ap, use_gl=use_gl, figures=False,counter=counter)
  counter+=1

inputs = []

#prepend silence to each wav
one_sec_segment = AudioSegment.silent(duration=int(randrange(1000,2000)))  #duration in milliseconds
for x in range(0,counter):
    filepath =  'configuration/voice/result/part' + str(x) + '.wav'
    audioFile = AudioSegment.from_wav(filepath)
    finalFile = audioFile + one_sec_segment 
    finalFile.export(filepath, format="wav")
    print("Filepath: " + filepath)
    inputs.append(filepath)

all_together = " ".join(inputs)
subprocess.call('sox ' + all_together + ' configuration/voice/final.wav', shell=True)


if os.path.exists('configuration/voice/result'):
	shutil.rmtree('configuration/voice/result')

os.makedirs('configuration/voice/result', exist_ok=True)

subprocess.call('ffmpeg -i configuration/voice/final.wav -af "lowpass=f=3000" configuration/voice/result/final.wav',shell=True)
os.remove('configuration/voice/final.wav')
